{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Welcome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This notebook accompanies the Sunokisis Digital Classics common session on Named Entity Extraction, see <https://github.com/SunoikisisDC/SunoikisisDC-2016-2017/wiki/Named-Entity-Extraction-I>.\n",
    "\n",
    "In this notebook we are going to experiment with three different methods for extracting named entities from a Latin text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Library imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "External modules and libraries can be imported using `import` statements.\n",
    "\n",
    "Let's the [Natural Language ToolKit (NLTK)](http://www.nltk.org/), the [Classical Language ToolKit (CLTK)](http://cltk.org/), [MyCapytain](http://mycapytain.readthedocs.io/en/latest/) and some local libraries that are used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "########\n",
    "# NLTK #\n",
    "########\n",
    "import nltk\n",
    "from nltk.tag import StanfordNERTagger\n",
    "########\n",
    "# CLTK #\n",
    "########\n",
    "import cltk\n",
    "from cltk.tag.ner import tag_ner\n",
    "##############\n",
    "# MyCapytain #\n",
    "##############\n",
    "import MyCapytain \n",
    "from MyCapytain.resolvers.cts.api import HttpCTSResolver\n",
    "from MyCapytain.retrievers.cts5 import CTS\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    "#################\n",
    "# other imports #\n",
    "#################\n",
    "import sys\n",
    "sys.path.append(\"/opt/nlp/pymodules/\")\n",
    "from idai_journals.nlp import sub_leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And more precisely, we are using the following versions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(cltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(MyCapytain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Let's grab some text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To start with, we need some text from which we'll try to extract named entities using various methods and libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "There are several ways of doing this e.g.:\n",
    "1. copy and paste the text from Perseus or the Latin Library into a text document, and read it into a variable\n",
    "2. load a text from one of the Latin corpora available via `cltk` (cfr. this [blog post](https://disiectamembra.wordpress.com/2016/05/29/cltk-importing-the-latin-library-as-a-corpus/))\n",
    "3. or load it from Perseus by leveraging its [Canonical Text Services]() API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's gor for #3 :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## What's CTS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "CTS URNs stand for Canonical Text Service Uniform Resource Names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can think of a CTS URN like a **social security number** for texts (or parts of texts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "![caption](imgs/cts_urn_syntax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here are some examples of CTS URNs with different levels of granularity:\n",
    "- `urn:cts:latinLit:phi0448` (Caesar)\n",
    "- `urn:cts:latinLit:phi0448.phi001` (Caesar's *De Bello Gallico*)\n",
    "- `urn:cts:latinLit:phi0448.phi001.perseus-lat2` DBG Latin edtion\n",
    "- `urn:cts:latinLit:phi0448.phi001.perseus-lat2:1` DBG Latin edition, book 1\n",
    "- `urn:cts:latinLit:phi0448.phi001.perseus-lat2:1.1.1` DBG Latin edition, book 1, chapter 1, section 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "How do I find out the CTS URN of a given author or text? The [Perseus Catalog](http://catalog.perseus.org/) is your friend! (crf. e.g. <http://catalog.perseus.org/catalog/urn:cts:latinLit:phi0448>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Querying a CTS API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The URN of the Latin edition of Caesar's **De Bello Gallico** is `urn:cts:latinLit:phi0448.phi001.perseus-lat2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_passage = \"urn:cts:latinLit:phi0448.phi001.perseus-lat2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "With this information, we can query a CTS API and get some information about this text.\n",
    "\n",
    "For example, we can \"discover\" its canonical text structure, an essential information to be able to *cite* this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# We set up a resolver which communicates with an API available in Leipzig\n",
    "resolver = HttpCTSResolver(CTS(\"http://cts.dh.uni-leipzig.de/api/cts/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resolver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c381671a60d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# We require some metadata information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtextMetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"urn:cts:latinLit:phi0448.phi001.perseus-lat2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Texts in CTS Metadata have one interesting property : its citation scheme.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Citation are embedded objects that carries information about how a text can be quoted, what depth it has\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcitation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcitation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtextMetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcitation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resolver' is not defined"
     ]
    }
   ],
   "source": [
    "# We require some metadata information\n",
    "textMetadata = resolver.getMetadata(\"urn:cts:latinLit:phi0448.phi001.perseus-lat2\")\n",
    "# Texts in CTS Metadata have one interesting property : its citation scheme.\n",
    "# Citation are embedded objects that carries information about how a text can be quoted, what depth it has\n",
    "print([citation.name for citation in textMetadata.citation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "But we can also query the same API and get back the text of a specific text section, for example the entire book 1.\n",
    "\n",
    "To do so, we need to append the indication of the reference scope (i.e. book 1) to the URN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "my_passage = \"urn:cts:latinLit:phi0448.phi001.perseus-lat2:1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "So we retrieve the first book of the **De Bello Gallico** by passing its CTS URN (that we just stored in the variable `my_passage`) to the CTS API, via the resolver provided by `MyCapytains`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "passage = resolver.getTextualNode(my_passage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "At this point the passage is available in various formats: text, but also TEI XML, etc.\n",
    "\n",
    "Thus, we need to specify that we are interested in getting the text only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "de_bello_gallico_book1 = passage.export(Mimetypes.PLAINTEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's check that the text is there by printing the content of the variable `de_bello_gallico_book1` where we stored it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(de_bello_gallico_book1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The text that we have just fetched by using a programming interface (API) can also be [viewed in the browser](http://cts.dh.uni-leipzig.de/read/latinLit/phi0448/phi001/perseus-lat2/1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Or even imported as an iframe into this notebook! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('http://cts.dh.uni-leipzig.de/read/latinLit/phi0448/phi001/perseus-lat2/1', width=1000, height=350)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's see how many words (tokens, more properly) there are in Caesar's *De Bello Gallico* I:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(de_bello_gallico_book1.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Very simple baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's write what in NLP jargon is called a *baseline*, that is a method for extracting named entities that can serve as a term of comparison to evaluate the accuracy of other methods. \n",
    "\n",
    "**Baseline method**: \n",
    "- cycle through each token of the text\n",
    "- if the token starts with a capital letter it's a named entity (only one type, i.e. `Entity`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"T\".istitle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"t\".istitle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'de_bello_gallico_book1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4f975478a4af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# tokenisation is done by using the string method `split(\" \")`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# that splits a string upon white spaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_bello_gallico_book1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mistitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtagged_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Entity\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'de_bello_gallico_book1' is not defined"
     ]
    }
   ],
   "source": [
    "# we need a list to store the tagged tokens\n",
    "tagged_tokens = []\n",
    "\n",
    "# tokenisation is done by using the string method `split(\" \")` \n",
    "# that splits a string upon white spaces\n",
    "for n, token in enumerate(de_bello_gallico_book1.split(\" \")):\n",
    "    if(token.istitle()):\n",
    "        tagged_tokens.append((token, \"Entity\"))\n",
    "    else:\n",
    "        tagged_tokens.append((token, \"O\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's a havea  look at the first 50 tokens that we just tagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagged_tokens[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For convenience we can also wrap our baseline code into a function that we call `extract_baseline`. Let's define it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_baseline(input_text):\n",
    "    \"\"\"\n",
    "    :param input_text: the text to tag (string)\n",
    "    :return: a list of tuples, where tuple[0] is the token and tuple[1] is the named entity tag\n",
    "    \"\"\"\n",
    "    # we need a list to store the tagged tokens\n",
    "    tagged_tokens = []\n",
    "\n",
    "    # tokenisation is done by using the string method `split(\" \")` \n",
    "    # that splits a string upon white spaces\n",
    "    for n, token in enumerate(input_text.split(\" \")):\n",
    "        if(token.istitle()):\n",
    "            tagged_tokens.append((token, \"Entity\"))\n",
    "        else:\n",
    "            tagged_tokens.append((token, \"O\")) \n",
    "    return tagged_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And now we can call it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'de_bello_gallico_book1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-beb152c3c999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtagged_tokens_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_bello_gallico_book1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'de_bello_gallico_book1' is not defined"
     ]
    }
   ],
   "source": [
    "tagged_tokens_baseline = extract_baseline(de_bello_gallico_book1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tagged_tokens_baseline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-829f79c2fbb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtagged_tokens_baseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tagged_tokens_baseline' is not defined"
     ]
    }
   ],
   "source": [
    "tagged_tokens_baseline[-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can modify slightly our function so that it prints the snippet of text where an entity is found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def extract_baseline(input_text):\n",
    "    \"\"\"\n",
    "    :param input_text: the text to tag (string)\n",
    "    :return: a list of tuples, where tuple[0] is the token and tuple[1] is the named entity tag\n",
    "    \"\"\"\n",
    "    # we need a list to store the tagged tokens\n",
    "    tagged_tokens = []\n",
    "\n",
    "    # tokenisation is done by using the string method `split(\" \")` \n",
    "    # that splits a string upon white spaces\n",
    "    for n, token in enumerate(input_text.split(\" \")):\n",
    "        if(token.istitle()):\n",
    "            tagged_tokens.append((token, \"Entity\"))\n",
    "            context = input_text.split(\" \")[n-5:n+5]\n",
    "            print(\"Found entity \\\"%s\\\" in context \\\"%s\\\"\"%(token, \" \".join(context)))\n",
    "        else:\n",
    "            tagged_tokens.append((token, \"O\"))  \n",
    "    return tagged_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'de_bello_gallico_book1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-918932ee4635>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtagged_text_baseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_bello_gallico_book1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'de_bello_gallico_book1' is not defined"
     ]
    }
   ],
   "source": [
    "tagged_text_baseline = extract_baseline(de_bello_gallico_book1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tagged_text_baseline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3f1a1261a358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtagged_text_baseline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tagged_text_baseline' is not defined"
     ]
    }
   ],
   "source": [
    "tagged_text_baseline[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# NER with CLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The CLTK library has some basic support for the extraction of named entities from Latin and Greek texts (see [CLTK's documentation](http://docs.cltk.org/en/latest/latin.html#named-entity-recognition)).\n",
    "\n",
    "The current implementation (as of version 0.1.47) uses a lookup-based method.\n",
    "\n",
    "For each token in a text, the tagger checks whether that token is contained within a predefined list of possible named entities:\n",
    "- list of Latin proper nouns: <https://github.com/cltk/latin_proper_names_cltk>\n",
    "- list of Greek proper nouns: <https://github.com/cltk/greek_proper_names_cltk>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's run CLTK's tagger (it takes a moment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "tagged_text_cltk = tag_ner('latin', input_text=de_bello_gallico_book1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's have a look at the ouput, only the first 10 tokens (by using the list slicing notation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagged_text_cltk[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The output looks slightly different from the one of our baseline function (the size of the tuples in the list varies). \n",
    "\n",
    "But we can write a function to fix this, we call it `reshape_cltk_output`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def reshape_cltk_output(tagged_tokens):\n",
    "    reshaped_output = []\n",
    "    for tagged_token in tagged_tokens:\n",
    "        if(len(tagged_token)==1):\n",
    "            reshaped_output.append((tagged_token[0], \"O\"))\n",
    "        else:\n",
    "            reshaped_output.append((tagged_token[0], tagged_token[1]))\n",
    "    return reshaped_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We apply this function to CLTK's output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagged_text_cltk = reshape_cltk_output(tagged_text_cltk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And the resulting output looks now ok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagged_text_cltk[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now let's compare the two list of tagged tokens by using a python function called `zip`, which allows us to read multiple lists simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "list(zip(tagged_text_baseline[:20], tagged_text_cltk_reshaped[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "But, as you can see, the two lists are not aligned.\n",
    "\n",
    "This is due to how the CLTK function tokenises the text. The comma after \"tres\" becomes a token on its own, whereas when we tokenise by white space the comma is attached to \"tres\" (i.e. \"tres,\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "A solution to this is to pass to the `tag_ner` function the text already tokenised by text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagged_text_cltk = reshape_cltk_output(tag_ner('latin', input_text=de_bello_gallico_book1.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(zip(tagged_text_baseline[:20], tagged_text_cltk[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# NER with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stanford_model_italian = \"/opt/nlp/stanford-tools/stanford-ner-2015-12-09/classifiers/ner-ita-nogpe-noiob_gaz_wikipedia_sloppy.ser.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ner_tagger = StanfordNERTagger(stanford_model_italian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagged_text_nltk = ner_tagger.tag(de_bello_gallico_book1.split(\" \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's have a look at the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "tagged_text_nltk[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Wrap up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "At this point we can \"compare\" the output of the three different methods we used, again by using the `zip` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "list(zip(tagged_text_baseline[:20], tagged_text_cltk[:20], tagged_text_nltk[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for baseline_out, cltk_out, nltk_out in zip(tagged_text_baseline[:20], tagged_text_cltk[:20], tagged_text_nltk[:20]):\n",
    "    print(\"Baseline: %s\\nCLTK: %s\\nNLTK: %s\\n\"%(baseline_out, cltk_out, nltk_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Excercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Extract the named entities from the English translation of the *De Bello Gallico* book 1.\n",
    "\n",
    "The CTS URN for this translation is `urn:cts:latinLit:phi0448.phi001.perseus-eng2:1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Modify the code above to use the English model of the Stanford tagger instead of the italian one.\n",
    "\n",
    "Hint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stanford_model_english = \"/opt/nlp/stanford-tools/stanford-ner-2015-12-09/classifiers/english.muc.7class.distsim.crf.ser.gz\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "172px",
    "width": "303px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "693px",
    "left": "0px",
    "right": "1210px",
    "top": "106px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
